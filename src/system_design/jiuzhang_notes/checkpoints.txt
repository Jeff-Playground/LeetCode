Design Twitter:
    Timeline: includes activities from the user and interactions with other users
    News feed: included activities from the user's followed people
    Pull model
    Push model(fan-out)
    Combined model(distinguish normal users and celebrities)

Design user system:
    Session: used for authentication, a token/session_key will be sent back and forth for all requests
    Use cache to serve high QPS
    Do horizontal data sharding the avoid single point failure and increase performance
    Friendship can be stored either one-way or two-way

Design Tiny URL:
    To generate short_url based on long_url:
        hash function like MD5
        randomly generate string and check against DB short_url key
        Base62 on DB sequential ID
    To reduce response time:
        For reads, add cache, and set up distributed services based on user geographic locations(note only cache and related services need to be distributed)
        For writes, add more DB nodes and do consistent sharding
    To implement consistent sharding:
        sharding_key can be computed with a hash on long_url, like Hash(long_url)%62
        the short_url will include the sharding key, so it becomes sharding_key+short_url

Design distributed files system:
    Support read/write/update files, files are divided into chunks(When writing, division is done by client)
    Implemented in master-slave pattern:
        System health ensured by heartbeats
        Master stores metadata, including chunk server location, and in some cases offset(offset can be moved onto chunk servers instead)
        Slaves store actual file data in chunks, normally 64MB per chunk
            Chunks have replicas, not necessarily on the same 3 servers for each chunk
            A chunk can be validated using checksum mechanism
            Slaves are selected by LRU/High-free-space strategy by master for writes

Design a web crawler
    Producer-consumer pattern:
        Queue/buffer can be implemented using SQL DB
        Crawled results can be stored in NoSQL DB
    Handle update failure(website not updated):
        Exponential back-off
    Handle dead cycle(one website has too many web pages):
        Specify a quota and only crawl a certain percentage of all pages
    Handle websites in multiple regions:
        Set up the same system in every different region

Design a type-ahead system
    Trie:
        Two services involved, one for querying and the other for building the trie based on log
        Is read-only and new version need to be built offline regularly
        Can be implemented with NoSQL DB
        Can be stored distributively and accessed by consistent hashing
    Increase performance:
        Cache on frontend(cookies)
        Pre-fetch
    Reduce log size: probabilistic logging

Design a MapReduce system
    Master-slave
        Master is coordinator, slaves are map workers and reduce workers depends on the assigned job
        Slaves are initialized and in a pool
    The input and output on each step is basically a stream of key-value pairs
    Input and output of the system can be stored in a distributed file system for replications
    Map -> Shuffle -> Reduce
        Shuffle is done by both map and reduce workers
        Shuffle is sort and partition on map workers and merge sort and fetch on reduce workers
    When data for a specific key is too large, a trick of adding postfix to the key and partition it to different reducer workers can be implemented

Design Uber
    Server deployed in master-slave model as replications
    Both driver and user make requests to server
        Driver reports location within requests
        Response to driver may include trip info if a match is initiated
        User makes match request
        Response to user will have trip info and matched driver info
    Data can be sharded base on cities(Geo fence)

Design Bigtable
    File based
        Write/update:
            Load latest file into memory and make sorted, when write/update, write to WAL first, then write in sorted list in memory. The list should be persisted to file regularly
        Read:
            Add index to files, which can be implemented as B-tree
            Add bloom filter to file
    Master-slave
        Master contains key location info, implemented with consistent hashing
        Slave stores the actual data files
        Master monitors slaves with heartbeat mechanism
    File storage can use distributed file system for automatic replication, fail-over and recovery
        Files can also be cached on slave machines partially
    To handle race condition, use a distributed lock
        Chubby
        Zookeeper
        Consistent hashing info can be moved to lock server from master

Design WhatsApp
    Each user will be associated with a thread, where it contains info on: (SQL)
        thread_id
        owner_id
        nickname
        is_muted
        participants_id
        created_at
        updated_at
    Messages will be stored in NoSQL:
        message_id
        thread_id
        from_user_id
        to_user_id: used to identify @user in a group chat
        content
        created_at
    Active users will be assigned a socket connection to avoid delivery delays

Design a ratelimiter
    Implement with cache(Memcached/Redis)
        Key: event+feature+timestamp
            Key can be stored in different levels(seconds, minutes, hours, days, ...)
        Value: request counts
    For querying, it can be aggregated based upon a bunch of requests:
        For the time range, the closer it's to now, the lower level the query is
        An example for a request at 23:30:33, it will need to query for:
            23:30:00 ~ 23:30:33 on seconds(34 records)
            23:00:00 ~ 23:29:59 on minutes(30 records)
            00:00:00 ~ 22:59:59 on hours(23 records)
            23:31:00 ~ 23:59:59 on minutes(29 records)
            23:30:34 ~ 23:30:59 on seconds(26 records)
            So 34+30+23+29+26=142 in total
    Another possible solution is with Redis, two types of data type required:
        Hash: (Redis Hashes are maps between string fields and string values, just like java HashMap)
            Key: event+feature+unixTimestamp
            Value: request counts
        SortedSet: (Redis Sorted Sets are, similarly to Redis Sets, non repeating collections of Strings. The difference is that every member of a Sorted Set is associated with score, that is used in order to take the sorted set ordered, from the smallest to the greatest score.)
            Key: sorted_ratelimiter_keys
            Member: event+feature+unixTimestamp
            Score: unix timestamp

Design a datadog
    Implement log with SQL/NoSQL
    Implement organized request data with NoSQL/Cache
        Key: event+feature
        Value: a list of key value pairs(similar to how data is stored for ratelimiter):
            Key: timestamp
            Value: request counts
    To handle high QPS, instead of log every request, requests can be aggregated in memory for a certain period of time(15s for example) before writing to DB

