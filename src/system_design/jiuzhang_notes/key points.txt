How to pick server based on QPS:
    Webserver: 1k QPS
    SQL DB: 1k QPS
    NoSQL DB: 10k QPS
    Cache: 1m QPS

Storage types:
    Memory only
    SQL Database
    NoSQL Database
    File system

SQL vs NoSQL:
    SQL suppots transactions better
    SQL is more mature, while in NoSQL some things need to be taken care by user(serialization, secondary index)
    NoSQL normally has better performance
    NoSQL normally doesn't support multi-indexes
    NoSQL comes with sharding, while in SQL sharding has to be handled by developers

Session:
    Can be used for authentication
    Normally contains session_key/token, user_id, ttl, etc.
    token will be sent back and forth for authentication

Cache:
    LRU/LFU for updating cache
    Memcached(cache aside): memory only, better performance stability and scalability
    Redis(cache through): supports physical persistence
    Operation order: normally delete from cache first, then save to database

Single point of failure:
    Sharding: distribute data to different nodes, one node down won't bring down the whole system
        Vertical sharding: divide data by columns
        Horizontal sharding: divide data by key range
            Consistent hashing
    Replica: distributes reads to more nodes, and increase data safety
        Master-slave: master for writes and reads, slave for reads only

Consistent hashing
    Adding a node wouldn't change much of the original nodes, so it's consistent
    Hashing ring range: 0 ~ 2^64-1(Java Long.MAX_VALUE)
    Micro shards/Virtual nodes:
        each machine can be mapped to a lot of(for example 1000) micro shards on the ring
        each micro shard is a node/value on the ring
        When computing the machine location of a value, just hash it to map to a node on the ring, and find the first existing node on the ring clock-wise
            e.g. Hash(value)=location, lookup location in TreeMap(RBTree) to find the corresponding machine
        When adding a new machine, each new node would get part of the data from the first existing node clock-wise on the ring

Backup vs. Replica
    Backup:
        static, and is done on a regular basis at a scheduled time
        when data loss occurs, it can only recover to one of the backup time snapshot
        it's offline and not used for read requests
    Replica:
        real-time, is done while doing write requests to multiple copies
        when data loss occurs, it can use one of the duplicate nodes for recovering immediately
        it's online and can be used for read requests
        it's more expensive than backup
        SQL replica: master-slave, WAL
        NoSQL replica: same data stored on 3 consecutive virtual nodes belong to 3 different machines on hashing ring

What happens when opening a URL in browser?
1. Request goes to closest DNS server, where it has mapping info on the IP for the given domain name
2. Browser send HTTP/HTTPS request to the looked up IP
3. Destination webserver receive the request and give it to the HTTP server listening on port 80
4. The HTTP server sends the request to the web application
5. Web application handles the request and return a response
6. Browser get the response

Communication between servers:
    Peer-to-peer:
        Advantages:
            No single point of failure
        Disadvantages:
            Hard to keep consistency of data
    Master-slave:
        For DB: master supports read/write, slaves are read-only replicas
        For GFS/HDFS: master is the coordinator, where slaves stores files/data
        Advantages:
            Relatively easier to keep consistency of data
            Easy to set up
        Disadvantages:
            Single master is a single point of failure

File:
    What's in a file:
        Metadata: it's read more often than the actual file data
        Data
    How can a file be stored in one single machine:
        Sequentially (Windows)
        Fragmented: file data is separated into chunks (Linux)
            Disk is separated into blocks:
                Easy to check for errors
                Fragmentation
            Within metadata, there's a index on the block locations of the file chunks
                Make a chunk big:
                    Advantages: reduce the size of metadata
                    Disadvantages: for small files it's wasting some disk space

How multiple threads work together on shared resource:
    Sleep(exponential back-off)
    Condition variable(lock/mutex)
    Semaphore(allows a maximum of pre-defined number of threads to access the resource)

MapReduce:
MapReduce is a programing model and an associated implementation for processing and generating big data sets with a parallel, distributed algorithm on a cluster.
1. Input
2. Split
3. Map
Step 4 and 5 together is also called shuffle:
4. Sort and partition, where partition is to prepare for keys to be fetched to different reduce machines
    Done on the map machines
    Here sort is external sorting as data is too large to be completely read into memory
    Here partition is basically a hash function which takes key as input and outputs partition id
5. Merge and fetch, merge sort is similar to merge k sorted list
    Done on the reduce machines
6. Reduce
    The maximum number of reduce machines is the number of keys
7. Output
Master-slave:
Whole process step by step:
1. (Start)User program start master and workers.
2. (Assign Task)Master assign task to the map workers and reduce workers. (Assign Map and Reduce code)
3. (Split)Master split the input data.
4. (Map Read)Each map worker read the split input data.
5. (Map)Each map worker does the "Map" job on its machine.
6. (Map Output)Each map worker outputs the file in it's local disk.
7. (Reduce Fetch)Each reduce worker fetches the data from the map workers.
8. (Reduce)Each reducer worker does the "Reduce" job on its machine.
9. (Reduce Output)Reduce workers output the final output data.

Algorithms for location querying and matching:
    Google S2:
        Hilbert curve
        Location to a number
    Geohash:
        Peano curve
        Base32
        Location to a string

Socket:
    heartbeat is not enforced for socket, but here heartbeat should be used for ensuring user active
    socket on server side will use single listening port and distinguish connections by client side ip/port
    socket on client side will occupy one port and can't share it

